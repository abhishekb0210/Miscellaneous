<b>Goal</b>: We're dealing with a time-series dataset requiring multiple time series features prediction for each time unit. The goal is to find out the next 30 mins of air quality metrics which includes: CO, NO, PM10, PM 2.5. <br>
The approach I've followed is as follows:<br>
<b>a. Data Collection</b>: Collected the hourly data for London. Since the data is available for specific sub-regions in London, I have trim down the requirement for one such sub-region : London N. Kensington. Similar approach can be applied for all required sub-regions of Central London and the mean all regions could be used for the final prediction. The data is available at hourly level and hence prediction cannot be done for minutes, I'm predicting next 30 hours in the notebook. The API used for the data collection is : https://uk-air.defra.gov.uk/. The data has been collected from July 1,2015 till June 30, 2020.<br>
<b>b. Data Cleaning</b>:  Some cleaning steps include:<br>
<ul><li> Removing unwanted columns</li>
<li>Imputing NaNs or "No data" values using linear interpolation</li>
<li> Handling outliers using standard deviation. Replacing values greater that max allowed standard deviation with max standard deviation value and similarly replacing values smaller than the minimum standard deviation value with minimum standard deviation value.</li></ul>
<b>c. Exploratory Data Analysis</b>: Used auto-correlation plots to understand the data better and then subsequently applied data differences to generate stationary data and remove trends.<br>
<b>d. Feature Engineering</b>: Created custom features for month, day of the week and hour. Generated the sine and cosine variations of the above.<br>
<b>e. Model Training</b>: Some of the models tried are as follows:<br>
<ul><li> VAR: Vector Autoregression Model - Complete statistical approach which learns from past data</li>
<li> LSTM : based on neural networks and can learn from the past data</li>
<li> LSTM with VAR: First trained on VAR and then used</li>
<li> Bidirectional LSTM</li></ul>
		
**Model selection**: Final selected model is "LSTM with VAR", the results rendered by selected were much more aligned to real data than the VAR. VAR learns the internal behavior of our multivariate data source adjusting the insane values, correcting the anomalous trends. We made use of the VAR fitted values and passed them an input to LSTM and then subsequently retrained the LSTM on original data. The error generated by this approach are lower in comparison to what the plain LSTM model did. Graph in the notebook reflects the same. Also applied dropout during LSTM training to handle the forgetting problem while being trained on multi-steps.<br>
		
**f. Prediction**: Post training the model, retrained the final selected model using the complete data. Made use of that model predict the unforeseen data. Created custom features for future days and then predicted one by one. A simple function call can be used to predict the next set of 30 hours of data. The prediction can be generated using the function - predict_future<br>

#### Future work and improvements:
a. Handle outliers better<br>
b. Apply the same approach to all sub-regions of Central London and then calculate the mean to predict the final value<br>
c. Hyperparameter tuning of the model<br>
d. Try Decision tree models like Random Forest and compare the results with our 2-step model of LSTM with VAR<br>
e. Retrain the final model on complete data and use it for prediction<br>
